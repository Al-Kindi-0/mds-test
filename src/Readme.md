The following note documents some ideas that might be of use for generating circulant MDS matrices over finite fields. For implementation purposes, it is usually desirable to have the elements of the matrix be small when viewed as natural numbers compared against the modulus of the field.

# The brute-force approach
The brute-force approach samples the first row of the circulant matrix at random in the increasing range $[1, p-1]$. From this row, the other rows of the matrix, say $A$, are generated by left (or right) modular shifts.
Once $A$ is generated, the next step is testing whether $A$ is MDS by testing that all its (sub-) minors are non-zero. This "MDS-ness" test is the most expensive part of the brute-force approach.
The advantage of the brute-force approach is the control over the size of the coefficients as sampling starts from $1$. Moreover, in the case where one aims at implementing a matrix-vector product using FFT using Nabaglo's technique, further conditions are usually imposed on the sampled coefficients in what can be termed their "frequency-domain" representation.

# Using Reed-Solomon codes
As proposed by Alan Szepieniec and Ulrich Habock, independently, one can use RS-codes to construct MDS matrices. This approach has the draw-back of loss of control over the size the elements of the generated matrix. This can lead to significant degradation in performance of the FFT-based matrix-vector multiplication procedure.

# Testing MDS-ness
The complexity of testing that a matrix $A$ is MDS has exponential complexity in the dimension of $A$. A natural question is then:
Can we leverage the fact that the matrix is circulant in order to design a faster MDS test for circulant matrices?
The answer is a yes and was given in the work of [Malakhov](https://arxiv.org/abs/2110.13325) where the author proposes an algorithm that produces a subset of the set of all minors with the duplications resulting from the circulant-matrix structure quotiend out. The resulting set over which the MDS-ness test is performed has size $\frac{\mu}{2 n}$ where $\mu$ is the size of all minors and $n$ is the number of columns/rows of $A$. An advantage of this algorithm is related to the fact that this "pre-processing" step needs to be done only once for a given dimension $n$. Another advantage is that we can use minors of smaller size to compute minors of a larger size as the list of minors produced in the pre-processing step has a nested structure along the rows (See proposition 5 in [Malakhov](https://arxiv.org/abs/2110.13325)).
For example, these improvements combine to make testing MDS-ness of matrices as large as $18\times 18$ possible on a mid-range laptop.

# The brute-force approach: revisited
The above improved MDS-ness test makes the brute-force approach potentially viable for matrices (hopefully!) as large as $24\times 24$ with a few tweaks.
The problem with trying rows with random coefficients and then testing is that the likelihood of passing the MDS-ness test in this case is very small. In small dimensions, say less than $16$, this is not a big deal as the MDS-ness test is relatively fast i.e. only a couple of seconds on a laptop for dimension $16\times 16$. When the dimension of the matrix is large, the random guessing approach is likely to remain impractical even with the new MDS-ness test. Instead, we can make an educated guess using:

## Concatentation: 
We can generate a list of rows representing $12 \times 12$ circulant matrices with the desired properties e.g. "low weight". From this list, we then select $2$ rows at random and construct a row of length $24$ and only then do we test for MDS-ness. This approach was used in order to generate the matrix of size $16\times 16$ with first row $[38, 29, 18, 1, 18, 20, 7, 1, 22, 27, 2, 29, 50, 52, 5, 65]$ from a list of rows of size $12$ generated during the RPO project. Note that further necessary condition that are cheap to test can be performed before doing the MDS-ness test. The following work by [Malakhov and Rozkhov](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=pdm&paperid=767&option_lang=eng) proposes a result in this direction.

## RS on small fields:
We can use the RS-based approach in order to generate a candidate tow with small weights by working initially over a very small field e.g. $257$. Then, we can go on to test MDS-ness over the original field. This is the approach used in order to generate the matrix of size $24\times 24$ with first row $[1, 53, 173, 21, 138, 56, 51, 183, 75, 60, 208, 238, 143, 86, 151, 223, 192, 66, 54, 158, 8, 32, 40, 167]$ that is a (potential!) MDS matrix. The matrix was tested for MDS-ness for minors of size up to $5$ on my laptop. A very interesting question to investigate related to this method is: under which conditions can one transfer the MDS-ness property from one field to another? After running a few experiments, it seems that an MDS matrix defined on an initial field is very likely to remain MDS when defining it over a larger field.

# Code:

The following [code](https://github.com/Al-Kindi-0/mono) implements these ideas in the context of the `Monolith` hash function on the $2^{31} - 1$ prime. The concatenation method was used in order to generate the $16\times 16$ matrix, while the RS-over-small-field approach was used in order to generate the $24 \times 24$ matrix. We noticed a $-9$% reduction in time for the $16$ case and a $-75$% reduction in time in the $24$ case.
